{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2278629d",
   "metadata": {},
   "source": [
    "### Step 1: Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98b9e605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Loading the dataset\n",
    "df = pd.read_csv('questions.csv')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4bdeb",
   "metadata": {},
   "source": [
    "### Step 2: Data Preparation and Cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771ca218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading the dataset\n",
    "df = pd.read_csv('questions.csv')  \n",
    "\n",
    "# Step 2.1: Basic Cleaning\n",
    "df_clean = df.dropna(subset=['question1', 'question2'])\n",
    "\n",
    "# Converting to string\n",
    "df_clean['question1'] = df_clean['question1'].astype(str)\n",
    "df_clean['question2'] = df_clean['question2'].astype(str)\n",
    "\n",
    "# Step 2.2: Extracting unique questions using pandas\n",
    "# Combining both question columns into one series\n",
    "all_questions_series = pd.concat([\n",
    "    df_clean['question1'], \n",
    "    df_clean['question2']\n",
    "], ignore_index=True)\n",
    "\n",
    "# Getting unique questions \n",
    "unique_questions = all_questions_series.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Step 2.3: Creating questions database\n",
    "questions_db = pd.DataFrame({\n",
    "    'question_id': range(len(unique_questions)),\n",
    "    'question_text': unique_questions\n",
    "})\n",
    "\n",
    "# Adding metadata\n",
    "questions_db['question_length'] = questions_db['question_text'].str.len()\n",
    "questions_db['word_count'] = questions_db['question_text'].str.split().str.len()\n",
    "\n",
    "# Step 2.4: Saving files\n",
    "questions_db.to_csv('unique_questions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a10d574",
   "metadata": {},
   "source": [
    "### Step 3: SBERT Embeddings Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cdd10e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# Step 4.1: Load the pre-trained SBERT model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # Fast and good quality\n",
    "\n",
    "# Step 4.2: Load your prepared questions\n",
    "questions_df = pd.read_csv('unique_questions.csv')\n",
    "\n",
    "# For testing, let's start with a smaller batch\n",
    "BATCH_SIZE = 20000  \n",
    "questions_sample = questions_df.head(BATCH_SIZE).copy()\n",
    "\n",
    "questions_list = questions_sample['question_text'].tolist()\n",
    "\n",
    "# Step 4.3: Generate embeddings with progress tracking\n",
    "start_time = time.time()\n",
    "\n",
    "# Generate embeddings in batches to avoid memory issues\n",
    "batch_size = 500  # Process 500 questions at a time\n",
    "embeddings_list = []\n",
    "\n",
    "for i in range(0, len(questions_list), batch_size):\n",
    "    batch = questions_list[i:i+batch_size]\n",
    "    batch_embeddings = model.encode(batch, \n",
    "                                   convert_to_tensor=False,\n",
    "                                   show_progress_bar=False)\n",
    "    embeddings_list.extend(batch_embeddings)\n",
    "\n",
    "# Convert to numpy array\n",
    "embeddings = np.array(embeddings_list)\n",
    "end_time = time.time()\n",
    "\n",
    "# Step 4.4: Save embeddings and metadata\n",
    "\n",
    "# Save embeddings\n",
    "np.save('question_embeddings.npy', embeddings)\n",
    "\n",
    "# Save metadata\n",
    "embeddings_metadata = {\n",
    "    'model_name': 'all-MiniLM-L6-v2',\n",
    "    'embedding_dim': embeddings.shape[1],\n",
    "    'num_questions': embeddings.shape[0],\n",
    "    'generation_time': end_time - start_time,\n",
    "    'batch_size': BATCH_SIZE\n",
    "}\n",
    "\n",
    "with open('embeddings_metadata.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings_metadata, f)\n",
    "\n",
    "# Save the questions with IDs for reference\n",
    "questions_sample.to_csv('processed_questions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d491688",
   "metadata": {},
   "source": [
    "### Step 4:  Implement Cosine Similarity Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "546881cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "class QuestionSimilarityFinder:\n",
    "    def __init__(self):\n",
    "        self.embeddings = None\n",
    "        self.questions_df = None\n",
    "        self.model = None\n",
    "        self.metadata = None\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load all necessary data and models\"\"\"\n",
    "        \n",
    "        # Load embeddings\n",
    "        self.embeddings = np.load('question_embeddings.npy')\n",
    "        \n",
    "        # Load questions\n",
    "        self.questions_df = pd.read_csv('processed_questions.csv')\n",
    "        \n",
    "        # Load model for encoding new questions\n",
    "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        \n",
    "        # Load metadata\n",
    "        with open('embeddings_metadata.pkl', 'rb') as f:\n",
    "            self.metadata = pickle.load(f)\n",
    "        \n",
    "    def find_similar_questions(self, query_question, top_k=5, similarity_threshold=0.8):\n",
    "        \"\"\"\n",
    "        Find the most similar questions to a given query\n",
    "        \n",
    "        Args:\n",
    "            query_question (str): The question to find similarities for\n",
    "            top_k (int): Number of top similar questions to return\n",
    "            similarity_threshold (float): Minimum similarity score to consider\n",
    "            \n",
    "        Returns:\n",
    "            list: List of similar questions with their similarity scores\n",
    "        \"\"\"\n",
    "        #print(f\"\\n=== FINDING SIMILAR QUESTIONS ===\")\n",
    "        #print(f\"Query: '{query_question}'\")\n",
    "        \n",
    "        # Encode the query question\n",
    "        start_time = time.time()\n",
    "        query_embedding = self.model.encode([query_question])\n",
    "        \n",
    "        # Calculate cosine similarity with all questions\n",
    "        similarities = cosine_similarity(query_embedding, self.embeddings)[0]\n",
    "        \n",
    "        # Get top-k similar questions\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        results = []\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            similarity_score = similarities[idx]\n",
    "            if similarity_score >= similarity_threshold:\n",
    "                question_data = self.questions_df.iloc[idx]\n",
    "                results.append({\n",
    "                    'rank': i + 1,\n",
    "                    'question_id': question_data['question_id'],\n",
    "                    'question_text': question_data['question_text'],\n",
    "                    'similarity_score': similarity_score,\n",
    "                    'question_length': question_data['question_length'],\n",
    "                    'word_count': question_data['word_count']\n",
    "                })\n",
    "        \n",
    "        #print(f\"‚úì Search completed in {end_time - start_time:.4f} seconds\")\n",
    "        #print(f\"‚úì Found {len(results)} similar questions above threshold ({similarity_threshold})\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def display_results(self, results):\n",
    "        \"\"\"Display search results in a formatted way\"\"\"\n",
    "        if not results:\n",
    "            #print(\"No similar questions found above the threshold.\")\n",
    "            return\n",
    "            \n",
    "        #print(\"\\n\" + \"=\"*80)\n",
    "        #print(\"SIMILAR QUESTIONS FOUND:\")\n",
    "        #print(\"=\"*80)\n",
    "        \n",
    "        #for result in results:\n",
    "            #print(f\"\\nRank {result['rank']} | Similarity: {result['similarity_score']:.4f}\")\n",
    "            #print(f\"Question: {result['question_text']}\")\n",
    "            #print(f\"Stats: {result['word_count']} words, {result['question_length']} characters\")\n",
    "            #print(\"-\" * 60)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422ea538",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63e09b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox, scrolledtext\n",
    "from PIL import Image, ImageTk\n",
    "import threading\n",
    "\n",
    "\n",
    "class QuestionSimilarityFinderGUI:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Question Similarity Finder\")\n",
    "        self.root.geometry(\"700x600\")\n",
    "        self.root.configure(bg=\"#f6fff6\")\n",
    "\n",
    "        self.finder = QuestionSimilarityFinder()\n",
    "        self.finder.load_data()\n",
    "\n",
    "        self.create_widgets()\n",
    "\n",
    "    def create_widgets(self):\n",
    "        # GIF Image\n",
    "        try:\n",
    "            gif_img = Image.open(\"assets/Astronaut with space shuttle.gif\")\n",
    "            gif_img = gif_img.resize((150, 150))\n",
    "            self.gif_photo = ImageTk.PhotoImage(gif_img)\n",
    "            gif_label = tk.Label(self.root, image=self.gif_photo, bg=\"#f6fff6\")\n",
    "            gif_label.pack(pady=(10, 0))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Input field\n",
    "        self.input_entry = tk.Entry(self.root, font=(\"Segoe UI\", 12), width=70)\n",
    "        self.input_entry.pack(pady=10)\n",
    "\n",
    "        # Buttons\n",
    "        button_frame = tk.Frame(self.root, bg=\"#f6fff6\")\n",
    "        button_frame.pack(pady=5)\n",
    "\n",
    "        search_btn = tk.Button(button_frame, text=\"Search\", bg=\"#165497\", fg=\"white\", font=(\"Segoe UI\", 10, \"bold\"),\n",
    "                               width=10, command=self.search_thread)\n",
    "        search_btn.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        clear_btn = tk.Button(button_frame, text=\"Clear\", bg=\"#DC3545\", fg=\"white\", font=(\"Segoe UI\", 10, \"bold\"),\n",
    "                              width=10, command=self.clear_output)\n",
    "        clear_btn.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        # Output area\n",
    "        self.output_box = scrolledtext.ScrolledText(self.root, font=(\"Segoe UI\", 10), wrap=tk.WORD, width=85, height=20,\n",
    "                                                    bg=\"#ffffff\", bd=2, relief=\"solid\")\n",
    "        self.output_box.pack(pady=15)\n",
    "        self.output_box.config(state=tk.DISABLED)\n",
    "\n",
    "    def search_thread(self):\n",
    "        threading.Thread(target=self.search_question).start()\n",
    "\n",
    "    def search_question(self):\n",
    "        query = self.input_entry.get().strip()\n",
    "        self.clear_output()\n",
    "        if not query:\n",
    "            self.show_output(\"‚ö†Ô∏è Please enter a valid question.\")\n",
    "            return\n",
    "\n",
    "        self.show_output(\"üîç Searching for similar questions...\\n\")\n",
    "        try:\n",
    "            results = self.finder.find_similar_questions(query, top_k=5, similarity_threshold=0.7)\n",
    "            if not results:\n",
    "                self.show_output(\"‚ö†Ô∏è No similar questions found above threshold.\")\n",
    "            else:\n",
    "                formatted = self.format_results(results)\n",
    "                self.show_output(formatted)\n",
    "        except Exception as e:\n",
    "            self.show_output(f\"‚ùå Error: {str(e)}\")\n",
    "\n",
    "    def format_results(self, results):\n",
    "        output = \"\"\n",
    "        for result in results:\n",
    "            output += (\n",
    "                f\"üîπ Rank {result['rank']}\\n\"\n",
    "                f\"   Question: {result['question_text']}\\n\"\n",
    "                f\"   Similarity: {result['similarity_score']:.4f}\\n\\n\"\n",
    "            )\n",
    "        return output\n",
    "\n",
    "    def show_output(self, text):\n",
    "        self.output_box.config(state=tk.NORMAL)\n",
    "        self.output_box.insert(tk.END, text + \"\\n\")\n",
    "        self.output_box.config(state=tk.DISABLED)\n",
    "\n",
    "    def clear_output(self):\n",
    "        self.output_box.config(state=tk.NORMAL)\n",
    "        self.output_box.delete(1.0, tk.END)\n",
    "        self.output_box.config(state=tk.DISABLED)\n",
    "        self.input_entry.delete(0, tk.END)\n",
    "\n",
    "# --- Run App ---\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = QuestionSimilarityFinderGUI(root)\n",
    "    root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
